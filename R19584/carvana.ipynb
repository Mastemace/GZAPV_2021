{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "carvana.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNHmRMdMMQa-"
      },
      "source": [
        "# Print GPU info\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnXuUIesVnYu"
      },
      "source": [
        "# Get & unzip data\n",
        "!rm -rf ../content/*\n",
        "!wget https://graphicwg.irafm.osu.cz/storage/carvana.zip --no-check-certificate\n",
        "!unzip -q carvana.zip\n",
        "!rm carvana.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaX6kBgTYD4X"
      },
      "source": [
        "# Install dependencies\n",
        "!pip install segmentation_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49roQR6aZT0n"
      },
      "source": [
        "# Set environment variable so segmentation_models uses correct Keras\n",
        "%env SM_FRAMEWORK = tf.keras\n",
        "\n",
        "# Import libraries\n",
        "import segmentation_models as sm\n",
        "import cv2\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import albumentations as A\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uroXonqaUcA"
      },
      "source": [
        "# Create & compile model\n",
        "model = sm.Unet(\"resnet50\", classes=2, input_shape=(320, 480, 3), encoder_weights=None)\n",
        "model.compile(\"Adam\", sm.losses.DiceLoss())"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKbAiGBbkP_o"
      },
      "source": [
        "# Load data and labels into RAM\n",
        "def load_data(data_folder, label_folder):\n",
        "  data_paths = sorted(glob(data_folder + \"*.*\"))\n",
        "  data = [cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB) for path in tqdm(data_paths, desc=\"Loading data from '\" + data_folder + \"'\")]\n",
        "\n",
        "  labels_paths = [path.replace(data_folder, label_folder).replace(\".jpg\", \"_mask.png\") for path in data_paths]\n",
        "  labels = [cv2.imread(path, 0) for path in tqdm(labels_paths, desc=\"Loading labels from '\" + label_folder + \"'\")]\n",
        "\n",
        "  return data, labels\n",
        "\n",
        "x_train, y_train = load_data('./train/', './train_masks/')\n",
        "x_valid, y_valid = load_data('./valid/', './valid_masks/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNA7qmVCOYVH"
      },
      "source": [
        "# Augment image\n",
        "def augment(image, label):\n",
        "  t = A.Compose([\n",
        "                 A.OneOf([\n",
        "                          A.RandomBrightness(),\n",
        "                          A.RandomContrast(),\n",
        "                          A.RandomGamma(),\n",
        "                          A.Rotate()\n",
        "                 ])\n",
        "  ])\n",
        "\n",
        "  augmented = t(image=image, mask=label)\n",
        "\n",
        "  aug_image = augmented['image']\n",
        "  aug_label = augmented['mask']\n",
        "\n",
        "  if bool(random.getrandbits(1)):\n",
        "\n",
        "    MAX_HUE = 179\n",
        "\n",
        "    image_hue_changed = aug_image.copy()\n",
        "    hsv_image = cv2.cvtColor(image_hue_changed, cv2.COLOR_RGB2HSV)\n",
        "    random_h = random.randint(0, MAX_HUE)\n",
        "    hsv_image[..., 0] = (hsv_image[..., 0] + random_h) % MAX_HUE\n",
        "\n",
        "    image_hue_changed = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "    aug_image[aug_label[..., 0] == 0] = image_hue_changed[aug_label[..., 0] == 0]\n",
        "\n",
        "  return aug_image, aug_label"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIMXwiJ6HhS_"
      },
      "source": [
        "# Train sizes\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "STEPS_PER_EPOCH = len(x_train) // BATCH_SIZE\n",
        "VALIDATION_STEPS = len(x_valid) // BATCH_SIZE\n",
        "\n",
        "EPOCHS = 20"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcKV2OMEF3x4"
      },
      "source": [
        "# Data generator wrappers, 'cause you can't have parameters in function called with Keras train\n",
        "def data_generator_wrapper_train():\n",
        "    return data_generator(True)\n",
        "\n",
        "def data_generator_wrapper_valid():\n",
        "    return data_generator(False)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQLDYB-9E2Uq"
      },
      "source": [
        "# Data generator\n",
        "def data_generator(is_train):\n",
        "    while True:\n",
        "        g_images = []\n",
        "        g_labels = []\n",
        "        for b in range(BATCH_SIZE):\n",
        "            g_im, g_la = get_random_image_and_label(is_train)\n",
        "\n",
        "            g_im, g_la = augment(g_im, g_la)\n",
        "\n",
        "            g_images.append(g_im)\n",
        "                  \n",
        "            mask = np.zeros((g_la.shape[0], g_la.shape[1], 2))\n",
        "            mask[..., 0] = g_la == 0\n",
        "            mask[..., 1] = g_la == 255\n",
        "            g_labels.append(mask)\n",
        "            \n",
        "        g_images = np.asarray(g_images, dtype=float)\n",
        "        g_labels = np.asarray(g_labels, dtype=float)\n",
        "\n",
        "        yield g_images, g_labels"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC8H5hRKLpng"
      },
      "source": [
        "# Get random image (with coresponding label)\n",
        "def get_random_image_and_label(is_train):\n",
        "    train_size = len(x_train)\n",
        "    valid_size = len(x_valid)\n",
        "    if is_train:\n",
        "        index = random.randrange(0, train_size)\n",
        "        g_im, g_la = x_train[index], y_train[index]\n",
        "    else:\n",
        "        index = random.randrange(0, valid_size)\n",
        "        g_im, g_la = x_valid[index], y_valid[index]\n",
        "\n",
        "    return g_im, g_la"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scc_tnYWEhrX",
        "outputId": "c8c21ae5-e5b0-4c27-8e3e-d19474406071"
      },
      "source": [
        "# Train\n",
        "lro = ReduceLROnPlateau(patience=1, verbose=1)\n",
        "\n",
        "history = model.fit(data_generator_wrapper_train(),\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_data=data_generator_wrapper_valid(),\n",
        "          epochs=EPOCHS,\n",
        "          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "          validation_steps=VALIDATION_STEPS,\n",
        "          callbacks=[lro])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "110/611 [====>.........................] - ETA: 9:32 - loss: 0.2638"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}